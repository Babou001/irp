# =============================================================================
# Dockerfile.prod - Production build with embedded models
# =============================================================================
# This Dockerfile creates a self-contained image with all models included.
# Perfect for air-gapped/restricted environments (no internet required).
#
# Image size: ~6-7 GB (includes Llama 3.2 3B Q5 + all-mpnet-base-v2)
#
# Build: docker build -f Dockerfile.prod -t rag-system:prod .
# Run:   docker-compose -f docker-compose.prod.yml up
# =============================================================================

# Multi-stage build for optimal image size
FROM python:3.11-slim as builder

# Set working directory
WORKDIR /app

# Install system dependencies for building
RUN apt-get update && apt-get install -y \
    build-essential \
    wget \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .

# Create virtual environment and install dependencies
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Install Python packages
RUN pip install --no-cache-dir --upgrade pip setuptools wheel && \
    pip install --no-cache-dir -r requirements.txt

# Download spaCy model
RUN python -m spacy download en_core_web_lg

# =============================================================================
# Final stage - Production image
# =============================================================================
FROM python:3.11-slim

# Install runtime dependencies only
RUN apt-get update && apt-get install -y \
    libgomp1 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv

# Set environment variables
ENV PATH="/opt/venv/bin:$PATH" \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1

# Create non-root user
RUN useradd -m -u 1000 appuser && \
    mkdir -p /app/data /app/uploads /app/preprocessed_data && \
    chown -R appuser:appuser /app

# Set working directory
WORKDIR /app

# Copy application code (excluding models initially)
COPY --chown=appuser:appuser *.py ./
COPY --chown=appuser:appuser streamlit_pages/ ./streamlit_pages/
COPY --chown=appuser:appuser .streamlit/ ./.streamlit/
COPY --chown=appuser:appuser requirements.txt ./

# =============================================================================
# MODELS: Copy embedding and LLM models into the image
# =============================================================================
# This is what makes the image self-contained (but larger)
COPY --chown=appuser:appuser models/ ./models/

# Verify models are present
RUN ls -lh /app/models/ && \
    echo "âœ… Models successfully embedded in image"

# Create necessary directories
RUN mkdir -p /app/images /app/videos && \
    chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Expose ports
# 8000 for FastAPI
# 8501 for Streamlit
EXPOSE 8000 8501

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/', timeout=5)" || exit 1

# Default command (can be overridden in docker-compose)
CMD ["uvicorn", "fast_api_app:app", "--host", "0.0.0.0", "--port", "8000"]
